# Moderation-Application

This repository presents the final project, which involves building a deep learning model (or a model of models) for comment moderation on a blog site. The goal is to classify user comments as either normal or toxic. If a comment is toxic, the model provides detailed reasons, such as sexually explicit content, harm to minority or religious communities, offensive language towards the LGBTQ community, derogatory remarks on physical appearance, and bashing cast and creeds.
